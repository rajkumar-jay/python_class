{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9xOXaRKHDnS"
      },
      "source": [
        "# Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9IFLV7RCDbY"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I73nT5HJHQxs",
        "outputId": "51f48d0c-c5ed-48e5-b613-1f02b3828605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs shape: (10, 5, 4)\n",
            "Final hidden state: [[ 0.99992061 -0.53241266  0.97776873  0.99625996  0.99749836 -0.9865753\n",
            "   0.99999736 -0.99999083 -0.84912118 -0.98479046  0.99989618 -0.55951793\n",
            "   0.97921091 -0.93687535  0.03623493 -0.99940157]\n",
            " [-0.97750003 -0.99964098  0.99829995 -0.99644913  0.99999717 -0.99999838\n",
            "  -0.96556781 -0.62797337 -0.99951779  0.75212183 -0.46313882 -0.99999998\n",
            "   0.81389376  0.99999975 -0.58907662  0.98217242]\n",
            " [-0.99920993 -0.99992106  0.6041345   0.99935821 -0.99923363  1.\n",
            "   0.99681646  0.99998412  1.         -0.99897739  0.99998622  0.99998329\n",
            "   0.95285693  0.01964777 -0.97059064  0.30119457]\n",
            " [-0.9999082   1.         -0.99687831  0.72509085 -0.84332214 -0.98789455\n",
            "  -0.99999869 -0.7656342  -1.          0.68401024  0.05019231  0.40167074\n",
            "  -0.99996899  0.99870984 -0.98768952  0.98429731]\n",
            " [ 0.99998125 -0.9999371   0.91446432  0.99957131  0.99999915 -0.99904088\n",
            "   0.99998317 -0.86649913 -0.98816753 -0.20944004  0.99699267 -1.\n",
            "   0.80935848  0.99773768 -0.99955606 -0.40769349]]\n"
          ]
        }
      ],
      "source": [
        "class SimpleRNN:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "     self.hidden_size = hidden_size\n",
        "     self.Wx = np.random.randn(input_size, hidden_size)\n",
        "     self.Wh = np.random.randn(hidden_size, hidden_size)\n",
        "     self.Wy = np.random.randn(hidden_size, output_size)\n",
        "     self.bh = np.zeros((1, hidden_size))\n",
        "     self.by = np.zeros((1, output_size))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    h = np.zeros((inputs.shape[0], self.hidden_size))\n",
        "    outputs = []\n",
        "\n",
        "    for t in range(inputs.shape[1]):\n",
        "      h = np.tanh(np.dot(inputs[:, t, :], self.Wx) + np.dot(h, self.Wh) + self.bh)\n",
        "      y = np.dot(h, self.Wy) + self.by\n",
        "      outputs.append(y)\n",
        "    return np.array(outputs), h\n",
        "\n",
        "inputs = np.random.randn(5, 10, 8)\n",
        "rnn = SimpleRNN(input_size=8, hidden_size=16, output_size=4)\n",
        "\n",
        "outputs, h = rnn.forward(inputs)\n",
        "\n",
        "print(\"Outputs shape:\", outputs.shape)\n",
        "print(\"Final hidden state:\", h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3bK_zErHFp8"
      },
      "source": [
        "Hands-on\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxEVDIR7K8un"
      },
      "source": [
        "# Hands-on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_H5ENf3K-4l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lm6g37BLq0Z",
        "outputId": "e6fc2fa4-3530-4cf1-c893-37af3444f1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
            "\u001b[1m5618815/5618815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
        "text_path = tf.keras.utils.get_file('shakespeare.txt', url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLgsiXv4L8Gv"
      },
      "outputs": [],
      "source": [
        "text = open(text_path, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8wyiN1LMFbT"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {char: idx for idx, char in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wy5t7-YMxxl"
      },
      "outputs": [],
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNh6v8pOM-QX"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text) // seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk1H4hL2NNYH"
      },
      "outputs": [],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwmusSALNkTn"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBBOumHsOLeU"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huCuAo90OiJi"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pfUZ_6FOwvm",
        "outputId": "d2efa0bc-6253-47ac-cfb3-bb35d64ad2ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=seq_length),\n",
        "    SimpleRNN(rnn_units, return_sequences=True),\n",
        "    Dense(vocab_size)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2-dUVZUPNyN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "d6H45X4JPgBl",
        "outputId": "f888edc7-fab1-4d25-9b51-8b7469a3d396"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZNjW2dsPnxk",
        "outputId": "b7cf3bbb-a97f-443c-b070-ad8aeeefa59e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1574s\u001b[0m 2s/step - loss: 4.8631\n",
            "Epoch 2/10\n",
            "\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1562s\u001b[0m 2s/step - loss: 4.5012\n",
            "Epoch 3/10\n",
            "\u001b[1m254/859\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:22\u001b[0m 2s/step - loss: 4.7629"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(dataset, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxG5l5S5P27W"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 1000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "  model.reset_states()\n",
        "      for _ in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)\n",
        "\n",
        "print(generate_text(model, start_string=\"ROMEO: \"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}